{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cxRpHVRyCgTc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running on CoLab\n"
     ]
    }
   ],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    print('Running on CoLab')\n",
    "\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')   \n",
    "\n",
    "    import os\n",
    "    os.chdir('/content/drive/My Drive/Deep_learning_project/')\n",
    "\n",
    "else:\n",
    "    print('Not running on CoLab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "MYrsLzZQCdaG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions import Normal\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import datetime\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from modules import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "mDvvHO62CdaW"
   },
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "tjLhbjw8Cdae"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('GM_preparedData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "fY7y0jVPCdaq"
   },
   "outputs": [],
   "source": [
    "# Define rectangle where \"valid data belongs\":\n",
    "\n",
    "upper_right = (55.880120, 12.707644)\n",
    "lower_left = (55.548626, 12.061736)\n",
    "\n",
    "# Clean data\n",
    "df_clean = df.loc[(df['startPositionLat'] >= lower_left[0]) & (df['startPositionLat']<=upper_right[0])]\n",
    "df_clean = df_clean.loc[(df_clean['startPositionLng'] >= lower_left[1]) & (df_clean['startPositionLng']<=upper_right[1])]\n",
    "\n",
    "df_clean = df_clean.loc[(df_clean['endPositionLat'] >= lower_left[0]) & (df_clean['endPositionLat']<=upper_right[0])]\n",
    "df_clean = df_clean.loc[(df_clean['endPositionLng'] >= lower_left[1]) & (df_clean['endPositionLng']<=upper_right[1])]\n",
    "\n",
    "df_clean = df_clean.dropna(\n",
    "    axis=0, \n",
    "    subset=['startPositionLat', 'startPositionLng', 'endPositionLat', 'endPositionLng']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "meoj74bEMDPW"
   },
   "outputs": [],
   "source": [
    "data_columns = ['startPositionLng', 'startPositionLat', 'endPositionLng', 'endPositionLat']\n",
    "data = df_clean[data_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "IRbhdNsKL8wd"
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(data.values, test_size=0.1, random_state=42)\n",
    "df_train = pd.DataFrame(train, columns=data.columns)\n",
    "df_test = pd.DataFrame(test, columns=data.columns)\n",
    "\n",
    "#Normalize training data\n",
    "mu_lat_start = df_train['startPositionLat'].mean()\n",
    "sig_lat_start = df_train['startPositionLat'].std()\n",
    "\n",
    "mu_lng_start = df_train['startPositionLng'].mean()\n",
    "sig_lng_start = df_train['startPositionLng'].std()\n",
    "\n",
    "mu_lat_end = df_train['endPositionLat'].mean()\n",
    "sig_lat_end = df_train['endPositionLat'].std()\n",
    "\n",
    "mu_lng_end = df_train['endPositionLng'].mean()\n",
    "sig_lng_end = df_train['endPositionLng'].std()\n",
    "\n",
    "df_train['NormLngStart'] = df_train['startPositionLng'].apply(lambda x: (x-mu_lng_start)/sig_lng_start)\n",
    "df_train['NormLatStart'] = df_train['startPositionLat'].apply(lambda x: (x-mu_lat_start)/sig_lat_start)\n",
    "\n",
    "df_train['NormLngEnd'] = df_train['endPositionLng'].apply(lambda x: (x-mu_lng_end)/sig_lng_end)\n",
    "df_train['NormLatEnd'] = df_train['endPositionLat'].apply(lambda x: (x-mu_lat_end)/sig_lat_end)\n",
    "\n",
    "# Normalize validation set\n",
    "test_mu_lat_start = df_test['startPositionLat'].mean()\n",
    "test_sig_lat_start = df_test['startPositionLat'].std()\n",
    "\n",
    "test_mu_lng_start = df_test['startPositionLng'].mean()\n",
    "test_sig_lng_start = df_test['startPositionLng'].std()\n",
    "\n",
    "test_mu_lat_end = df_test['endPositionLat'].mean()\n",
    "test_sig_lat_end = df_test['endPositionLat'].std()\n",
    "\n",
    "test_mu_lng_end = df_test['endPositionLng'].mean()\n",
    "test_sig_lng_end = df_test['endPositionLng'].std()\n",
    "\n",
    "df_test['NormLngStart'] = df_test['startPositionLng'].apply(lambda x: (x-test_mu_lng_start)/test_sig_lng_start)\n",
    "df_test['NormLatStart'] = df_test['startPositionLat'].apply(lambda x: (x-test_mu_lat_start)/test_sig_lat_start)\n",
    "\n",
    "df_test['NormLngEnd'] = df_test['endPositionLng'].apply(lambda x: (x-test_mu_lng_end)/test_sig_lng_end)\n",
    "df_test['NormLatEnd'] = df_test['endPositionLat'].apply(lambda x: (x-test_mu_lat_end)/test_sig_lat_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "nMsD56GINkNF"
   },
   "outputs": [],
   "source": [
    "data_train = df_train[['NormLngStart', 'NormLatStart', 'NormLngEnd', 'NormLatEnd']]\n",
    "data_test = df_test[['NormLngStart', 'NormLatStart', 'NormLngEnd', 'NormLatEnd']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vkrVvKQ8Cda7"
   },
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "3w4Ve807CdbI"
   },
   "outputs": [],
   "source": [
    "mu = torch.zeros(4).to(device)\n",
    "sigma = torch.ones(4).to(device)\n",
    "base = Normal(mu, sigma)\n",
    "\n",
    "net = RealNVP(in_features=4, prior=base, hidden_features=256, depth=6).to(device)\n",
    "optimizer = torch.optim.Adam([p for p in net.parameters() if p.requires_grad], lr=1e-4)\n",
    "\n",
    "pyro_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, patience=25, verbose=True)\n",
    "\n",
    "# Arbitrary clipping value to suppress exploding gradients\n",
    "clipping_value = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "GtJCDu5LCdbi"
   },
   "outputs": [],
   "source": [
    "X_train = torch.Tensor(data_train.values).to(device)\n",
    "X_test = torch.Tensor(data_test.values).to(device)\n",
    "\n",
    "train_dataset = TensorDataset(X_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [00:21<2:58:54, 21.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 1.2166879177093506\n",
      "Train loss: -0.5792530259079128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [00:27<3:45:28, 27.11s/it]\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "validation_losses = []\n",
    "save_flag = True\n",
    "epochs = 500\n",
    "\n",
    "try:\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        loss_epoch = 0\n",
    "\n",
    "        # VALIDATION\n",
    "        net.eval()\n",
    "\n",
    "        validation_loss = -torch.mean(net.log_likelihood(X_test))\n",
    "        validation_losses.append(validation_loss.item())\n",
    "        \n",
    "        pyro_scheduler.step(validation_loss)\n",
    "\n",
    "        # TRAIN LOOP\n",
    "        net.train()\n",
    "        for batch_num, (X_batch) in enumerate(train_loader):\n",
    "            X_batch = X_batch[0]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss = -torch.mean(net.log_likelihood(X_batch))\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_epoch += loss.item()\n",
    "\n",
    "        loss_epoch = loss_epoch / (batch_num+1)\n",
    "        train_losses.append(loss_epoch)\n",
    "\n",
    "        if (epoch) % 1 == 0:\n",
    "            print(f'Validation loss: {validation_loss}')\n",
    "            print(f'Train loss: {loss_epoch}')\n",
    "\n",
    "        if (epoch) % 50 == 0:\n",
    "            torch.save(net.state_dict(), 'model_state_fix_prior_pickup_cond_updated_epoch_%d.pth' % (epoch+1))\n",
    "    \n",
    "    if save_flag:\n",
    "        loss_dict = {'validation': validation_losses, 'train': train_losses}\n",
    "        with open('loss_dict_pickup_cond_fix_prior.pkl', 'wb') as f:\n",
    "            pickle.dump(loss_dict, f)\n",
    "\n",
    "        torch.save(net.state_dict(), 'model_state_pickup_fix_prior_cond.pth')\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    if save_flag:\n",
    "        loss_dict = {'validation': validation_losses, 'train': train_losses}\n",
    "        with open('loss_dict_pickip_cond_fix_prior.pkl', 'wb') as f:\n",
    "            pickle.dump(loss_dict, f)\n",
    "\n",
    "        torch.save(net.state_dict(), 'model_state_fix_prior_pickup_cond.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Pickup Conditioned NF.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
